{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: [Alper AhmetoÄŸlu](https://www.github.com/alper111)\n",
    "\n",
    "I hereby declare that I observed the honour code of the university when preparing the homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pr?gr?mm?ng?H?m?w?rk\n",
    "\n",
    "In this exercise we model a string of text using a Markov(1) model. For simplicity we only consider letters 'a-z'. Capital letters 'A-Z' are mapped to the corresponding ones. All remaining letters, symbols, numbers, including spaces, are denoted by '.'.\n",
    "\n",
    "\n",
    "We have a probability table $T$ where $T_{i,j} = p(x_t = j | x_{t-1} = i)$  transition model of letters in English text for $t=1,2 \\dots N$. Assume that the initial letter in a string is always a space denoted as $x_0 = \\text{'.'}$. Such a model where the probability table is always the same is sometimes called a stationary model.\n",
    "\n",
    "1. For a given $N$, write a program to sample random strings with letters $x_1, x_2, \\dots, x_N$ from $p(x_{1:N}|x_0)$\n",
    "1. Now suppose you are given strings with missing letters, where each missing letter is denoted by a question mark (or underscore, as below). Implement a method, that samples missing letters conditioned on observed ones, i.e., samples from $p(x_{-\\alpha}|x_{\\alpha})$ where $\\alpha$ denotes indices of observed letters. For example, if the input is 't??.', we have $N=4$ and\n",
    "$x_1 = \\text{'t'}$ and $x_4 = \\text{'.'}$, $\\alpha=\\{1,4\\}$ and $-\\alpha=\\{2,3\\}$. Your program may possibly generate the strings 'the.', 'twi.', 'tee.', etc. Hint: make sure to make use all data given and sample from the correct distribution. Implement the method and print the results for the test strings below. \n",
    "1. Describe a method for filling in the gaps by estimating the most likely letter for each position. Hint: you need to compute\n",
    "$$\n",
    "x_{-\\alpha}^* = \\arg\\max_{x_{-\\alpha}} p(x_{-\\alpha}|x_{\\alpha})\n",
    "$$\n",
    "Implement the method and print the results for the following test strings along with the log-probability  $\\log p(x_{-\\alpha}^*,x_{\\alpha})$.\n",
    "1. Discuss how you can improve the model to get better estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_strings = ['th__br__n.f_x.', '_u_st__n_.to_be._nsw_r__','i__at_._a_h_n_._e_r_i_g','q___t.___z._____t.__.___.__.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: The code below loads a table of transition probabilities for English text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "alphabet = [chr(i+ord('a')) for i in range(26)]\n",
    "alphabet.append('.')\n",
    "letter2idx = {c:i for i,c in enumerate(alphabet)}\n",
    "\n",
    "T = []\n",
    "with open('transitions.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in reader:\n",
    "        T.append(row)\n",
    "T = np.array(T).astype(np.float).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $p(x_{1:N}|x_0) = p(x_1|x_0) p(x_2|x_1) \\dots p(x_N|x_{N-1})$, given $x_0$ I can draw a sample from $p(x_1|x_0)$ and repeat the process for the succeeding $x$'s. $p(x_n | x_{n-1})$ corresponds to transition probabilities of letters because we are dealing with a Markov(1) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_0(T, x_0, n):\n",
    "    string = alphabet[x_0]\n",
    "    x_t = x_0\n",
    "    for i in range(n):\n",
    "        x_t = np.random.multinomial(1, T[:,x_t]).argmax()\n",
    "        string = string + alphabet[x_t]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tithie.\n",
      "ng.t.f.\n",
      "d.wimp.\n",
      "arst.ba\n",
      "ond.rof\n",
      "vee.ofe\n",
      "per.gll\n",
      "f..ve.o\n",
      "bl.then\n",
      "sthisli\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(sample_0(T, np.random.randint(27), 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find $p(x_{-\\alpha}|x_{\\alpha})$, let's first try to find $p(x_t|x_{\\alpha})$. This is to calculate a missing letter in some position given some other letters. Our aim is to decompose $p(x_{-\\alpha}|x_{\\alpha})$. For example, we can decompose $p(x_2, x_3 | x_1, x_4)$ as $p(x_2|x_1, x_4) p(x_3|x_2, x_4)$ since after we know $x_2$, $x_1$ is d-seperated from $x_3$. So with this strategy we can first sample a letter for some position, then repeat this process for all missing letters. Each missing letter is dependent on their first known left and right letter. For the query: \"t_eb_ow___x\", first missing letter is dependent on \"t\" and \"e\", second missing letter is dependent on \"b\" and \"o\" and other missing letters are dependent on \"w\" and \"x\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_t(T, p_xleft, p_xright, it_left, it_right):\n",
    "    for i in range(it_left):\n",
    "        p_xleft = np.matmul(T, p_xleft)\n",
    "    \n",
    "    for i in range(it_right):\n",
    "        p_xright = np.matmul(p_xright, T)\n",
    "    p_all = p_xleft * p_xright\n",
    "    p_all = p_all / p_all.sum()\n",
    "    return p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_t(p_t):\n",
    "    x_t = np.random.multinomial(1, p_t).argmax()\n",
    "    return x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = np.eye(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_14 = prob_t(T, I[letter2idx['t']], I[letter2idx['h']], 1, 2)\n",
    "x3_24 = prob_t(T, I[letter2idx['a']], I[letter2idx['h']], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021103512341482107"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_14[letter2idx['a']] * x3_24[letter2idx['g']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3_14 = prob_t(T, I[letter2idx['t']], I[letter2idx['h']], 2, 1)\n",
    "x2_13 = prob_t(T, I[letter2idx['t']], I[letter2idx['g']], 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0021103512341482103"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_13[letter2idx['a']] * x3_14[letter2idx['g']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above calculation is a sanity check to verify that $p(x_2|x_1, x_4)p(x_3|x_2,x_4)=p(x_3|x_1,x_4)p(x_2|x_1,x_3)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_in(T, string):\n",
    "    string = '.' + string + '#'\n",
    "    filled = ''\n",
    "    for i, p in enumerate(string, 0):\n",
    "        if p != '_':\n",
    "            filled += p\n",
    "        else:\n",
    "            prev_idx = None\n",
    "            next_idx = None\n",
    "            it = i-1\n",
    "            while (prev_idx is None):\n",
    "                if string[it] != '_':\n",
    "                    prev_idx = it\n",
    "                else:\n",
    "                    it = it - 1\n",
    "            it = i+1\n",
    "            while (next_idx is None):\n",
    "                if string[it] != '_':\n",
    "                    next_idx = it\n",
    "                else:\n",
    "                    it = it + 1\n",
    "            if string[next_idx] == string[-1]:\n",
    "                filled += sample_0(T, letter2idx[string[prev_idx]],1)[1]\n",
    "            else:\n",
    "                p_i = prob_t(T, I[letter2idx[string[prev_idx]]], I[letter2idx[string[next_idx]]], i-prev_idx, next_idx-i)\n",
    "                idx = sample_t(p_i)\n",
    "                filled += alphabet[idx]\n",
    "    return filled[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\tth__br__n.f_x.\n",
      "Filled:\t\ttheabrzin.fix.\n",
      "Original:\t_u_st__n_.to_be._nsw_r__\n",
      "Filled:\t\ttunsth.nd.tombe.onswaro.\n",
      "Original:\ti__at_._a_h_n_._e_r_i_g\n",
      "Filled:\t\tir.ato..athind.cerr.ing\n",
      "Original:\tq___t.___z._____t.__.___.__.\n",
      "Filled:\t\tqut.t.berz.isl..t.ne.gtl.ao.\n"
     ]
    }
   ],
   "source": [
    "for s_t in test_strings:\n",
    "    print(\"Original:\\t%s\\nFilled:\\t\\t%s\" % (s_t, fill_in(T, s_t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. not finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_max(T, string):\n",
    "    first = string[0]\n",
    "    last = string[-1]\n",
    "    L = len(string)\n",
    "    p_0 = prob_t(T, I[start], I[end], 1, L-2)\n",
    "    if L > 3:\n",
    "        #Â time, (index, probs), letter\n",
    "        G = np.zeros(L, 2, 27)\n",
    "        G[0,0] =\n",
    "        for i in range(L):\n",
    "            E = T * p_0\n",
    "        \n",
    "    else:\n",
    "        logprob = np.log(p_0.max())\n",
    "        index = p_0.argmax()\n",
    "        return index, logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(10,3)\n",
    "x = np.ones(3) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.94839566,  1.55427901,  1.77319991],\n",
       "       [-0.4498723 ,  1.20508907, -1.70600363],\n",
       "       [-0.07442923,  0.91690361,  0.46028564],\n",
       "       [ 0.80209156, -0.75191864, -0.79929438],\n",
       "       [ 0.212488  , -0.62337984, -0.40318   ],\n",
       "       [ 0.7401259 , -0.72399075, -0.4523293 ],\n",
       "       [-0.50533241, -1.08004318, -0.59790201],\n",
       "       [ 0.1641342 , -0.84323622,  0.03595211],\n",
       "       [ 0.62312857,  0.68562197, -1.77750615],\n",
       "       [ 1.8841038 ,  0.07147979, -1.83160973]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.31959972,  3.6152672 ,  2.75071084,  2.40627469,  0.63746399,\n",
       "        2.22037769, -1.51599723,  0.49240259,  2.05686591,  5.65231139])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A*x).max(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
